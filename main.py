import threading
import pyttsx3
from PySide6.QtWidgets import QApplication, QMainWindow, QFileDialog, QMenu
from PySide6.QtGui import QImage, QPixmap, QColor
from PySide6.QtCore import QTimer, QThread, Signal, QObject, QPoint, Qt
import classes.yolo
from ui.CustomMessageBox import MessageBox
from ui.home import Ui_MainWindow
import json
import sys
import cv2
import os
from ui.utils.UIFunctions import *
from ui.utils.rtsp_win import Window
from ui.utils.tts_win import TTSWindow
# class YoloPredictor(BasePredictor, QObject):
#     # ä¿¡å·å®šä¹‰
#     yolo2main_pre_img = Signal(np.ndarray)  # åŸå§‹å›¾åƒä¿¡å·
#     yolo2main_res_img = Signal(np.ndarray)  # æµ‹è¯•ç»“æœä¿¡å·
#     yolo2main_status_msg = Signal(str)  # æ£€æµ‹/æš‚åœ/åœæ­¢/æµ‹è¯•å®Œæˆ/é”™è¯¯æŠ¥å‘Šä¿¡å·
#     yolo2main_fps = Signal(str)  # å¸§ç‡ä¿¡å·
#     yolo2main_labels = Signal(dict)  # æ£€æµ‹ç›®æ ‡ç»“æœï¼ˆæ¯ä¸ªç±»åˆ«çš„æ•°é‡ï¼‰
#     yolo2main_progress = Signal(int)  # è¿›åº¦ä¿¡å·
#     yolo2main_class_num = Signal(int)  # æ£€æµ‹åˆ°çš„ç±»åˆ«æ•°
#     yolo2main_target_num = Signal(int)  # æ£€æµ‹åˆ°çš„ç›®æ ‡æ•°
#     yolo2main_tts_dialog = Signal(int)  # ç«æºè­¦å‘Š
#     yolo2main_tts = Signal(int)
#
#     def __init__(self, cfg=DEFAULT_CFG, overrides=None):
#         super(YoloPredictor, self).__init__()
#         QObject.__init__(self)
#
#         # è·å–é…ç½®
#         self.args = get_cfg(cfg, overrides)
#         project = self.args.project or Path(SETTINGS['runs_dir']) / self.args.task
#         name = f'{self.args.mode}'
#         self.save_dir = increment_path(Path(project) / name, exist_ok=self.args.exist_ok)
#         self.done_warmup = False
#         if self.args.show:
#             self.args.show = check_imshow(warn=True)
#
#         # GUI å‚æ•°
#         self.used_model_name = None  # ä½¿ç”¨çš„æ£€æµ‹æ¨¡å‹åç§°
#         self.new_model_name = None  # å®æ—¶æ›´æ”¹çš„æ¨¡å‹
#         self.source = ''  # è¾“å…¥æº
#         self.stop_dtc = False  # ç»ˆæ­¢æ£€æµ‹
#         self.continue_dtc = True  # æš‚åœæ£€æµ‹
#         self.save_res = False  # ä¿å­˜æµ‹è¯•ç»“æœ
#         self.save_txt = False  # ä¿å­˜æ ‡ç­¾(txt)æ–‡ä»¶
#         self.iou_thres = 0.45  # IoU é˜ˆå€¼
#         self.conf_thres = 0.25  # ç½®ä¿¡åº¦é˜ˆå€¼
#         self.speed_thres = 10  # å»¶è¿Ÿï¼Œæ¯«ç§’
#         self.labels_dict = {}  # è¿”å›ç»“æœçš„å­—å…¸
#         self.progress_value = 0  # è¿›åº¦æ¡
#
#         # ä»…åœ¨é…ç½®è®¾ç½®å®Œæˆåå¯ç”¨
#         self.model = None
#         self.data = self.args.data  # data_dict
#         self.imgsz = None
#         self.device = None
#         self.dataset = None
#         self.vid_path, self.vid_writer = None, None
#         self.annotator = None
#         self.data_path = None
#         self.source_type = None
#         self.batch = None
#         self.callbacks = defaultdict(list, callbacks.default_callbacks)  # æ·»åŠ å›è°ƒå‡½æ•°
#         callbacks.add_integration_callbacks(self)
#
#         self.fire_flag = False  # æ˜¯å¦è¯†åˆ«åˆ°ç«ç„°
#         self.isFirstTTS = True  # æ˜¯å¦ä¸ºç¬¬ä¸€æ¬¡è¯†åˆ«åˆ°ç«ç„°
#
#     # ä¸»è¦æ£€æµ‹æ–¹æ³•
#     @smart_inference_mode()
#     def run(self):
#         # try:
#         if self.args.verbose:
#             LOGGER.info('')
#
#         # è®¾ç½®æ¨¡å‹
#         self.yolo2main_status_msg.emit('åŠ è½½æ¨¡å‹...')
#         if not self.model:
#             self.setup_model(self.new_model_name)
#             self.used_model_name = self.new_model_name
#
#         # è®¾ç½®è¾“å…¥æº
#         self.setup_source(self.source if self.source is not None else self.args.source)
#
#         # æ£€æŸ¥ä¿å­˜è·¯å¾„/æ ‡ç­¾
#         if self.save_res or self.save_txt:
#             (self.save_dir / 'labels' if self.save_txt else self.save_dir).mkdir(parents=True, exist_ok=True)
#
#         # é¢„çƒ­æ¨¡å‹
#         if not self.done_warmup:
#             self.model.warmup(imgsz=(1 if self.model.pt or self.model.triton else self.dataset.bs, 3, *self.imgsz))
#             self.done_warmup = True
#
#         self.seen, self.windows, self.dt, self.batch = 0, [], (ops.Profile(), ops.Profile(), ops.Profile()), None
#
#         # å¼€å§‹æ£€æµ‹
#         count = 0  # è¿è¡Œå®šä½å¸§
#         start_time = time.time()  # ç”¨äºè®¡ç®—å¸§ç‡
#         batch = iter(self.dataset)
#
#         while True:
#             # ç»ˆæ­¢æ£€æµ‹
#             if self.stop_dtc:
#                 if isinstance(self.vid_writer[-1], cv2.VideoWriter):
#                     self.vid_writer[-1].release()  # é‡Šæ”¾æœ€ç»ˆè§†é¢‘å†™å…¥å™¨
#                 self.yolo2main_status_msg.emit('Detection terminated!')
#                 break
#
#             # # åœ¨æ£€æµ‹è¿‡ç¨‹ä¸­æ›´æ”¹æ¨¡å‹
#             # if self.used_model_name != self.new_model_name:
#             #     # self.yolo2main_status_msg.emit('Change Model...')
#             #     self.setup_model(self.new_model_name)
#             #     self.used_model_name = self.new_model_name
#
#             # æš‚åœå¼€å…³
#             if self.continue_dtc:
#                 # time.sleep(0.001)
#                 self.yolo2main_status_msg.emit('Detecting...')
#                 batch = next(self.dataset)  # ä¸‹ä¸€ä¸ªæ•°æ®
#
#                 self.batch = batch
#                 path, im, im0s, vid_cap, s = batch
#
#                 visualize = increment_path(self.save_dir / Path(path).stem,
#                                            mkdir=True) if self.args.visualize else False
#
#                 # è®¡ç®—å®Œæˆåº¦å’Œå¸§ç‡ï¼ˆå¾…ä¼˜åŒ–ï¼‰
#                 count += 1  # å¸§è®¡æ•° +1
#                 if vid_cap:
#                     all_count = vid_cap.get(cv2.CAP_PROP_FRAME_COUNT)  # æ€»å¸§æ•°
#                 else:
#                     all_count = 1
#                 self.progress_value = int(count / all_count * 1000)  # è¿›åº¦æ¡(0~1000)
#                 if count % 5 == 0 and count >= 5:  # æ¯5å¸§è®¡ç®—ä¸€æ¬¡å¸§ç‡
#                     self.yolo2main_fps.emit(str(int(5 / (time.time() - start_time))))
#                     start_time = time.time()
#
#                 # é¢„å¤„ç†
#                 with self.dt[0]:
#                     im = self.preprocess(im)
#                     if len(im.shape) == 3:
#                         im = im[None]  # ä¸ºæ‰¹æ¬¡ç»´åº¦æ‰©å±•
#                 # æ¨ç†
#                 with self.dt[1]:
#                     preds = self.model(im, augment=self.args.augment, visualize=visualize)
#                 # åå¤„ç†
#                 with self.dt[2]:
#                     self.results = self.postprocess(preds, im, im0s)
#
#                 # å¯è§†åŒ–ã€ä¿å­˜ã€å†™å…¥ç»“æœ
#                 n = len(im)  # å¾…æ”¹è¿›: æ”¯æŒå¤šå¼ å›¾åƒ
#                 for i in range(n):
#                     self.results[i].speed = {
#                         'preprocess': self.dt[0].dt * 1E3 / n,
#                         'inference': self.dt[1].dt * 1E3 / n,
#                         'postprocess': self.dt[2].dt * 1E3 / n}
#                     p, im0 = (path[i], im0s[i].copy()) if self.source_type.webcam or self.source_type.from_img \
#                         else (path, im0s.copy())
#                     p = Path(p)  # æºç›®å½•
#
#                     # s:::   video 1/1 (6/6557) 'path':
#                     # must, to get boxs\labels
#                     label_str = self.write_results(i, self.results, (p, im, im0))  # æ ‡ç­¾å­—ç¬¦ä¸²   /// original :s +=
#
#                     # æ ‡ç­¾å’Œæ•°é‡
#                     class_nums = 0
#                     target_nums = 0
#                     self.labels_dict = {}
#                     if 'no detections' in label_str:
#                         pass
#                     else:
#                         for ii in label_str.split(',')[:-1]:
#                             nums, label_name = ii.split('~')
#                             self.labels_dict[label_name] = int(nums)
#                             target_nums += int(nums)
#                             # print('è­¦å‘Šï¼æ£€æµ‹åˆ°ç«æºï¼ï¼')
#                             self.fire_flag = True
#                             if self.fire_flag & self.isFirstTTS:
#                                 self.isFirstTTS = False
#                                 self.yolo2main_tts_dialog.emit(1)
#                                 self.yolo2main_tts.emit(1)
#
#                             class_nums += 1
#
#                     # ä¿å­˜å›¾åƒæˆ–è§†é¢‘ç»“æœ
#                     if self.save_res:
#                         self.save_preds(vid_cap, i, str(self.save_dir / p.name))
#
#                     # å‘é€æµ‹è¯•ç»“æœä¿¡å·
#                     self.yolo2main_res_img.emit(im0)  # æ£€æµ‹å
#                     self.yolo2main_pre_img.emit(im0s if isinstance(im0s, np.ndarray) else im0s[0])  # æ£€æµ‹å‰
#                     # self.yolo2main_labels.emit(self.labels_dict)        # webcam need to change the def write_results
#                     self.yolo2main_class_num.emit(class_nums)
#                     self.yolo2main_target_num.emit(target_nums)
#
#                     if self.speed_thres != 0:
#                         time.sleep(self.speed_thres / 1000)  # å»¶è¿Ÿï¼Œæ¯«ç§’
#
#                 self.yolo2main_progress.emit(self.progress_value)  # è¿›åº¦æ¡
#
#             # æ£€æµ‹å®Œæˆ
#             if count + 1 >= all_count:
#                 if isinstance(self.vid_writer[-1], cv2.VideoWriter):
#                     self.vid_writer[-1].release()  # é‡Šæ”¾æœ€ç»ˆè§†é¢‘å†™å…¥å™¨
#                 self.yolo2main_status_msg.emit('Detection completed')
#                 break
#
#     # except Exception as e:
#     #     pass
#     #     print(e)
#     #     self.yolo2main_status_msg.emit('%s' % e)
#
#     @smart_inference_mode()
#     def camera_run(self):
#         try:
#             if self.args.verbose:
#                 LOGGER.info('')
#
#             # set model
#             self.yolo2main_status_msg.emit('åŠ è½½æ¨¡å‹...')
#
#             if not self.model:
#                 self.setup_model(self.new_model_name)
#                 self.used_model_name = self.new_model_name
#
#             # æ£€æŸ¥ä¿å­˜è·¯å¾„/æ ‡ç­¾
#             if self.save_res or self.save_txt:
#                 (self.save_dir / 'labels' if self.save_txt else self.save_dir).mkdir(parents=True, exist_ok=True)
#
#             self.seen, self.windows, self.dt, self.batch = 0, [], (ops.Profile(), ops.Profile(), ops.Profile()), None
#             # åˆ›å»ºåä¸º dt çš„å®ä¾‹å˜é‡ï¼Œç”¨äºå­˜å‚¨ä¸€ä¸ªå…ƒç»„ï¼Œå¹¶å°†å…¶åˆå§‹åŒ–ä¸ºåŒ…å«ä¸‰ä¸ªå¯¹è±¡ ops.Profile() çš„å…ƒç»„ã€‚
#             # ops.Profile() æ˜¯æŒ‡ä» ops æ¨¡å—ä¸­å¯¼å…¥åä¸º Profile() çš„å¯¹è±¡ã€‚
#
#             # start detection
#
#             count = 0  # run location frame
#             start_time = time.time()  # used to calculate the frame rate
#
#             # ------------------
#             self.capture = cv2.VideoCapture(0)  # åˆ›å»ºä¸€ä¸ª OpenCV è§†é¢‘æ•è·å¯¹è±¡
#
#             while True:
#                 time.sleep(0.06)  # ä¼‘çœ  60 æ¯«ç§’ï¼ˆ0.06 ç§’ï¼‰
#                 ret, frame = self.capture.read()  # æ•è·æ‘„åƒå¤´çš„å›¾åƒ
#                 if ret:  # å¦‚æœè¯»å–æˆåŠŸ
#                     frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
#                     self.capture_frame = Image.fromarray(frame_rgb)
#
#                 print(self.capture_frame)
#                 self.setup_source(self.capture_frame)
#
#                 # warmup model
#                 # çƒ­èº«æ¨¡å‹
#                 if not self.done_warmup:
#                     # è°ƒç”¨æ¨¡å‹çš„ warmup å‡½æ•°ï¼Œå…¶ä¸­ imgsz å‚æ•°ä¸ºè¾“å…¥å›¾åƒçš„å¤§å°
#                     # å¦‚æœæ¨¡å‹ä½¿ç”¨ PyTorchï¼Œimgsz å‚æ•°åº”ä¸º [batch_size, channels, height, width]
#                     # å¦‚æœæ¨¡å‹ä½¿ç”¨ Tritonï¼Œimgsz å‚æ•°åº”ä¸º [height, width, channels, batch_size]
#                     self.model.warmup(
#                         imgsz=(1 if self.model.pt or self.model.triton else self.dataset.bs, 3, *self.imgsz))
#                     # å°† done_warmup æ ‡è®°ä¸º Trueï¼Œä»¥æ ‡è®°æ¨¡å‹å·²ç»çƒ­èº«è¿‡
#                     self.done_warmup = True
#
#                 batch = iter(self.dataset)
#
#                 # pause switch  ç”¨äºæ§åˆ¶ç¨‹åºçš„æš‚åœå’Œç»§ç»­
#                 if self.continue_dtc:
#                     # time.sleep(0.001)
#                     self.yolo2main_status_msg.emit('Detecting...')
#                     batch = next(self.dataset)  # next data
#
#                     self.batch = batch
#                     path, im, im0s, vid_cap, s = batch
#                     visualize = increment_path(self.save_dir / Path(path).stem,
#                                                mkdir=True) if self.args.visualize else False
#
#                     # Calculation completion and frame rate (to be optimized)
#                     count += 1  # frame count +1
#                     all_count = 1000  # all_count å¯ä»¥è°ƒæ•´ï¼ï¼ï¼
#                     self.progress_value = int(count / all_count * 1000)  # progress bar(0~1000)
#                     if count % 5 == 0 and count >= 5:  # Calculate the frame rate every 5 frames
#                         self.yolo2main_fps.emit(str(int(5 / (time.time() - start_time))))
#                         start_time = time.time()
#
#                     # preprocess
#                     # self.dt åŒ…å«äº†ä¸‰ä¸ª DetectorTime ç±»å‹çš„å¯¹è±¡ï¼Œè¡¨ç¤ºé¢„å¤„ç†ã€æ¨ç†å’Œåå¤„ç†æ‰€èŠ±è´¹çš„æ—¶é—´
#
#                     ## ä½¿ç”¨ with è¯­å¥è®°å½•ä¸‹ä¸‹ä¸€è¡Œä»£ç æ‰€èŠ±è´¹çš„æ—¶é—´ï¼Œself.dt[0] è¡¨ç¤ºè®°å½•é¢„å¤„ç†æ“ä½œæ‰€èŠ±è´¹çš„æ—¶é—´ã€‚
#                     with self.dt[0]:
#                         # è°ƒç”¨ self.preprocess æ–¹æ³•å¯¹å›¾åƒè¿›è¡Œå¤„ç†ï¼Œå¹¶å°†å¤„ç†åçš„å›¾åƒèµ‹å€¼ç»™ im å˜é‡ã€‚
#                         im = self.preprocess(im)
#                         # å¦‚æœ im çš„ç»´åº¦ä¸º 3ï¼ˆRGB å›¾åƒï¼‰ï¼Œåˆ™è¡¨ç¤ºè¿™æ˜¯ä¸€å¼ å•å¼ å›¾åƒï¼Œéœ€è¦å°†å…¶æ‰©å±•æˆ 4 ç»´ï¼ŒåŠ ä¸Š batch ç»´åº¦ã€‚
#                         if len(im.shape) == 3:
#                             im = im[None]  # expand for batch dim  æ‰©å¤§æ‰¹é‡è°ƒæš—
#                     # inference
#                     with self.dt[1]:
#                         # è°ƒç”¨æ¨¡å‹å¯¹å›¾åƒè¿›è¡Œæ¨ç†ï¼Œå¹¶å°†ç»“æœèµ‹å€¼ç»™ preds å˜é‡ã€‚
#                         preds = self.model(im, augment=self.args.augment, visualize=visualize)
#                     # postprocess
#                     with self.dt[2]:
#                         # è°ƒç”¨ self.postprocess æ–¹æ³•å¯¹æ¨ç†ç»“æœè¿›è¡Œåå¤„ç†ï¼Œå¹¶å°†ç»“æœä¿å­˜åˆ° self.results å˜é‡ä¸­ã€‚
#                         # å…¶ä¸­ preds æ˜¯æ¨¡å‹çš„é¢„æµ‹ç»“æœï¼Œim æ˜¯æ¨¡å‹è¾“å…¥çš„å›¾åƒï¼Œè€Œ im0s æ˜¯åŸå§‹å›¾åƒçš„å¤§å°ã€‚
#                         self.results = self.postprocess(preds, im, im0s)
#
#                     # visualize, save, write results
#                     n = len(im)  # To be improved: support multiple img
#
#                     for i in range(n):
#                         self.results[i].speed = {
#                             'preprocess': self.dt[0].dt * 1E3 / n,
#                             'inference': self.dt[1].dt * 1E3 / n,
#                             'postprocess': self.dt[2].dt * 1E3 / n
#                         }
#                         p, im0 = (path[i], im0s[i].copy()) if self.source_type.webcam or self.source_type.from_img \
#                             else (path, im0s.copy())
#
#                         p = Path(p)  # the source dir
#
#                         # s:::   video 1/1 (6/6557) 'path':
#                         # must, to get boxs\labels
#                         label_str = self.write_results(i, self.results, (p, im, im0))  # labels   /// original :s +=
#
#                         # labels and nums dict
#                         class_nums = 0
#                         target_nums = 0
#                         self.labels_dict = {}
#                         if 'no detections' in label_str:
#                             pass
#                         else:
#                             for ii in label_str.split(',')[:-1]:
#                                 nums, label_name = ii.split('~')
#
#                                 li = nums.split(':')[-1]
#
#                                 print(li)
#
#                                 self.labels_dict[label_name] = int(li)
#                                 target_nums += int(li)
#                                 class_nums += 1
#
#                         # save img or video result
#                         if self.save_res:
#                             self.save_preds(vid_cap, i, str(self.save_dir / p.name))
#
#                         # Send test results ã€å‘é€ä¿¡å· ç»™ label æ˜¾ç¤ºå›¾åƒã€‘
#                         self.yolo2main_res_img.emit(im0)  # after detection  ----------ç»“æœ
#                         self.yolo2main_pre_img.emit(im0s if isinstance(im0s, np.ndarray) else im0s[0])  # Before testing
#                         # self.yolo2main_labels.emit(self.labels_dict)        # webcam need to change the def write_results
#                         self.yolo2main_class_num.emit(class_nums)
#                         self.yolo2main_target_num.emit(target_nums)
#
#                         if self.speed_thres != 0:
#                             time.sleep(self.speed_thres / 1000)  # delay , ms
#
#                     self.yolo2main_progress.emit(self.progress_value)  # progress bar
#
#                 # Detection completed
#                 if count + 1 >= all_count:
#                     if isinstance(self.vid_writer[-1], cv2.VideoWriter):
#                         self.vid_writer[-1].release()  # release final video writer
#                     self.yolo2main_status_msg.emit('Detection completed')
#                     break
#
#         except Exception as e:
#
#             self.capture.release()  # é‡Šæ”¾è§†é¢‘è®¾å¤‡
#             print('error:', e)
#             self.yolo2main_status_msg.emit('%s' % e)
#
#     # è·å– Annotator å®ä¾‹
#     def get_annotator(self, img):
#         return Annotator(img, line_width=self.args.line_thickness, example=str(self.model.names))
#
#     # å›¾åƒé¢„å¤„ç†
#     def preprocess(self, img):
#         img = torch.from_numpy(img).to(self.model.device)
#         img = img.half() if self.model.fp16 else img.float()  # # uint8 è½¬ä¸º fp16/32
#         img /= 255  # 0 - 255 è½¬ä¸º 0.0 - 1.0
#         return img
#
#     # é¢„æµ‹ç»“æœåå¤„ç†
#     def postprocess(self, preds, img, orig_img):
#         ### important
#         preds = ops.non_max_suppression(preds,
#                                         self.conf_thres,
#                                         self.iou_thres,
#                                         agnostic=self.args.agnostic_nms,
#                                         max_det=self.args.max_det,
#                                         classes=self.args.classes)
#
#         results = []
#         for i, pred in enumerate(preds):
#             orig_img = orig_img[i] if isinstance(orig_img, list) else orig_img
#             shape = orig_img.shape
#             pred[:, :4] = ops.scale_boxes(img.shape[2:], pred[:, :4], shape).round()
#             path, _, _, _, _ = self.batch
#             img_path = path[i] if isinstance(path, list) else path
#             results.append(Results(orig_img=orig_img, path=img_path, names=self.model.names, boxes=pred))
#         return results
#
#     # å†™å…¥æ£€æµ‹ç»“æœ
#     def write_results(self, idx, results, batch):
#         p, im, im0 = batch
#         log_string = ''
#         if len(im.shape) == 3:
#             im = im[None]  # ä¸ºæ‰¹æ¬¡ç»´åº¦æ‰©å±•
#         self.seen += 1
#         imc = im0.copy() if self.args.save_crop else im0
#         if self.source_type.webcam or self.source_type.from_img:  # batch_size >= 1         # attention
#             log_string += f'{idx}: '
#             frame = self.dataset.count
#         else:
#             frame = getattr(self.dataset, 'frame', 0)
#         self.data_path = p
#         self.txt_path = str(self.save_dir / 'labels' / p.stem) + ('' if self.dataset.mode == 'image' else f'_{frame}')
#         # log_string += '%gx%g ' % im.shape[2:]         # !!! don't add img size~
#         self.annotator = self.get_annotator(im0)
#
#         det = results[idx].boxes  # TODO: make boxes inherit from tensors
#
#         if len(det) == 0:
#             return f'{log_string}(no detections), '  # if no, send this~~
#
#         for c in det.cls.unique():
#             n = (det.cls == c).sum()  # detections per class
#             log_string += f"{n}~{self.model.names[int(c)]},"  # {'s' * (n > 1)}, "   # don't add 's'
#         # now log_string is the classes ğŸ‘†
#
#         # å†™
#         for d in reversed(det):
#             cls, conf = d.cls.squeeze(), d.conf.squeeze()
#             if self.save_txt:  # å†™å…¥æ–‡ä»¶
#                 line = (cls, *(d.xywhn.view(-1).tolist()), conf) \
#                     if self.args.save_conf else (cls, *(d.xywhn.view(-1).tolist()))  # label format
#                 with open(f'{self.txt_path}.txt', 'a') as f:
#                     f.write(('%g ' * len(line)).rstrip() % line + '\n')
#             if self.save_res or self.args.save_crop or self.args.show or True:  # Add bbox to image(must)
#                 c = int(cls)  # integer class
#                 name = f'id:{int(d.id.item())} {self.model.names[c]}' if d.id is not None else self.model.names[c]
#                 label = None if self.args.hide_labels else (name if self.args.hide_conf else f'{name} {conf:.2f}')
#                 self.annotator.box_label(d.xyxy.squeeze(), label, color=colors(c, True))
#             if self.args.save_crop:
#                 save_one_box(d.xyxy,
#                              imc,
#                              file=self.save_dir / 'crops' / self.model.model.names[c] / f'{self.data_path.stem}.jpg',
#                              BGR=True)
#
#         return log_string

class MainWindow(QMainWindow, Ui_MainWindow):
    main2yolo_begin_sgl = Signal()  # ä¸»çª—å£å‘å‡ºçš„ä¿¡å·ï¼Œç”¨äºè§¦å‘Yoloå®ä¾‹æ‰§è¡Œ

    def __init__(self, parent=None):
        super(MainWindow, self).__init__(parent)
        # åŸºæœ¬ç•Œé¢è®¾ç½®
        self.setupUi(self)
        self.setAttribute(Qt.WA_TranslucentBackground)  # åœ†è§’é€æ˜
        self.setWindowFlags(Qt.FramelessWindowHint)  # è®¾ç½®çª—å£æ ‡å¿—: éšè—çª—å£è¾¹æ¡†
        UIFuncitons.uiDefinitions(self)
        # æ˜¾ç¤ºæ¨¡å—é˜´å½±
        UIFuncitons.shadow_style(self, self.Class_QF, QColor(162, 129, 247))
        UIFuncitons.shadow_style(self, self.Target_QF, QColor(251, 157, 139))
        UIFuncitons.shadow_style(self, self.Fps_QF, QColor(170, 128, 213))
        UIFuncitons.shadow_style(self, self.Model_QF, QColor(64, 186, 193))

        # è¯»å–æ¨¡å‹æ–‡ä»¶å¤¹
        self.pt_list = os.listdir('./models')
        self.pt_list = [file for file in self.pt_list if file.endswith('.pt')]
        self.pt_list.sort(key=lambda x: os.path.getsize('./models/' + x))  # æŒ‰æ–‡ä»¶å¤§å°æ’åº
        self.model_box.clear()
        self.model_box.addItems(self.pt_list)
        self.Qtimer_ModelBox = QTimer(self)  # Timer: Monitor model file changes every 2 seconds
        self.Qtimer_ModelBox.timeout.connect(self.ModelBoxRefre)
        self.Qtimer_ModelBox.start(2000)

        # è¯­éŸ³è­¦ç¤º
        self.engine = pyttsx3.init()  # è¯­éŸ³è­¦ç¤º
        self.engine_switch = True  # å¾ªç¯è­¦å‘Š

        # Yolo-v8 çº¿ç¨‹
        self.yolo_predict = classes.yolo.YoloPredictor()  # åˆ›å»ºä¸€ä¸ªYoloå®ä¾‹
        self.select_model = self.model_box.currentText()  # é»˜è®¤æ¨¡å‹
        self.yolo_predict.new_model_name = "./models/%s" % self.select_model
        self.yolo_thread = QThread()  # åˆ›å»ºYoloçº¿ç¨‹
        self.yolo_predict.yolo2main_pre_img.connect(lambda x: self.show_image(x, self.pre_video))
        self.yolo_predict.yolo2main_res_img.connect(lambda x: self.show_image(x, self.res_video))
        self.yolo_predict.yolo2main_status_msg.connect(lambda x: self.show_status(x))
        self.yolo_predict.yolo2main_fps.connect(lambda x: self.fps_label.setText(x))
        # self.yolo_predict.yolo2main_labels.connect(self.show_labels)                            
        self.yolo_predict.yolo2main_class_num.connect(lambda x: self.Class_num.setText(str(x)))
        self.yolo_predict.yolo2main_target_num.connect(lambda x: self.Target_num.setText(str(x)))
        self.yolo_predict.yolo2main_progress.connect(lambda x: self.progress_bar.setValue(x))
        self.yolo_predict.yolo2main_tts_dialog.connect(self.voice_announcement)
        self.yolo_predict.yolo2main_tts.connect(self.tts)
        self.main2yolo_begin_sgl.connect(self.yolo_predict.run)
        self.yolo_predict.moveToThread(self.yolo_thread)

        # æ¨¡å‹å‚æ•°
        self.model_box.currentTextChanged.connect(self.change_model)
        self.iou_spinbox.valueChanged.connect(lambda x: self.change_val(x, 'iou_spinbox'))  # iou box
        self.iou_slider.valueChanged.connect(lambda x: self.change_val(x, 'iou_slider'))  # iou scroll bar
        self.conf_spinbox.valueChanged.connect(lambda x: self.change_val(x, 'conf_spinbox'))  # conf box
        self.conf_slider.valueChanged.connect(lambda x: self.change_val(x, 'conf_slider'))  # conf scroll bar
        self.speed_spinbox.valueChanged.connect(lambda x: self.change_val(x, 'speed_spinbox'))  # speed box
        self.speed_slider.valueChanged.connect(lambda x: self.change_val(x, 'speed_slider'))  # speed scroll bar

        # æç¤ºçª—å£åˆå§‹åŒ–
        self.Class_num.setText('--')
        self.Target_num.setText('--')
        self.fps_label.setText('--')
        self.Model_name.setText(self.select_model)

        # é€‰æ‹©æ£€æµ‹æº
        self.src_file_button.clicked.connect(self.open_src_file)  # é€‰æ‹©æœ¬åœ°æ–‡ä»¶
        self.src_cam_button.clicked.connect(self.chose_cam)  # chose_cam
        self.src_rtsp_button.clicked.connect(self.chose_rtsp)  # chose_rtsp

        # å¼€å§‹æµ‹è¯•æŒ‰é’®
        self.run_button.clicked.connect(self.run_or_continue)  # å¼€å§‹/æš‚åœæµ‹è¯•æŒ‰é’®
        self.stop_button.clicked.connect(self.stop)  # ç»ˆæ­¢æµ‹è¯•æŒ‰é’®

        # Other function buttons
        self.save_res_button.toggled.connect(self.is_save_res)  # ä¿å­˜å›¾åƒé€‰é¡¹
        self.save_txt_button.toggled.connect(self.is_save_txt)  # ä¿å­˜æ ‡ç­¾é€‰é¡¹
        self.ToggleBotton.clicked.connect(lambda: UIFuncitons.toggleMenu(self, True))  # å·¦ä¾§å¯¼èˆªæŒ‰é’®
        self.settings_button.clicked.connect(lambda: UIFuncitons.settingBox(self, True))  # å³ä¸Šè§’è®¾ç½®æŒ‰é’®

        # åˆå§‹åŒ–
        self.load_config()

    # ä¸»çª—å£æ˜¾ç¤ºåŸå§‹å›¾åƒå’Œæ£€æµ‹ç»“æœçš„é™æ€æ–¹æ³•
    @staticmethod
    def show_image(img_src, label):
        try:
            ih, iw, _ = img_src.shape
            w = label.geometry().width()
            h = label.geometry().height()
            # ä¿æŒåŸå§‹æ•°æ®æ¯”ä¾‹
            if iw / w > ih / h:
                scal = w / iw
                nw = w
                nh = int(scal * ih)
                img_src_ = cv2.resize(img_src, (nw, nh))

            else:
                scal = h / ih
                nw = int(scal * iw)
                nh = h
                img_src_ = cv2.resize(img_src, (nw, nh))

            frame = cv2.cvtColor(img_src_, cv2.COLOR_BGR2RGB)
            img = QImage(frame.data, frame.shape[1], frame.shape[0], frame.shape[2] * frame.shape[1],
                         QImage.Format_RGB888)
            label.setPixmap(QPixmap.fromImage(img))

        except Exception as e:
            print(repr(e))

    # æ§åˆ¶å¼€å§‹/æš‚åœ
    def run_or_continue(self):
        if self.yolo_predict.source == '':
            self.show_status('è¯·åœ¨å¼€å§‹æ£€æµ‹å‰é€‰æ‹©è§†é¢‘æº...')
            self.run_button.setChecked(False)
        else:
            self.yolo_predict.stop_dtc = False
            if self.run_button.isChecked():
                self.run_button.setChecked(True)  # å¯åŠ¨æŒ‰é’®
                self.save_txt_button.setEnabled(False)  # åœ¨å¼€å§‹æ£€æµ‹åç¦æ­¢å‹¾é€‰å¹¶ä¿å­˜
                self.save_res_button.setEnabled(False)
                self.show_status('æ£€æµ‹ä¸­...')
                self.yolo_predict.continue_dtc = True  # æ§åˆ¶Yoloæ˜¯å¦æš‚åœ
                if not self.yolo_thread.isRunning():
                    self.yolo_thread.start()
                    self.main2yolo_begin_sgl.emit()

            else:
                self.yolo_predict.continue_dtc = False
                self.show_status("æš‚åœ...")
                self.run_button.setChecked(False)  # å¯åŠ¨æŒ‰é’®

    # åº•éƒ¨çŠ¶æ€æ ä¿¡æ¯
    def show_status(self, msg):
        self.status_bar.setText(msg)
        if msg == 'Detection completed' or msg == 'æ£€æµ‹å®Œæˆ':
            self.save_res_button.setEnabled(True)
            self.save_txt_button.setEnabled(True)
            self.run_button.setChecked(False)
            self.progress_bar.setValue(0)
            if self.yolo_thread.isRunning():
                self.yolo_thread.quit()  # ç»“æŸè¿›ç¨‹
        elif msg == 'Detection terminated!' or msg == 'æ£€æµ‹ç»ˆæ­¢':
            self.save_res_button.setEnabled(True)
            self.save_txt_button.setEnabled(True)
            self.run_button.setChecked(False)
            self.progress_bar.setValue(0)
            if self.yolo_thread.isRunning():
                self.yolo_thread.quit()  # ç»“æŸè¿›ç¨‹
            self.pre_video.clear()  # æ¸…ç©ºå›¾åƒæ˜¾ç¤º
            self.res_video.clear()
            self.Class_num.setText('--')
            self.Target_num.setText('--')
            self.fps_label.setText('--')

    # é€‰æ‹©æœ¬åœ°æ–‡ä»¶
    def open_src_file(self):
        config_file = 'config/fold.json'
        config = json.load(open(config_file, 'r', encoding='utf-8'))
        open_fold = config['open_fold']

        # å¦‚æœé…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„ä¸å­˜åœ¨ï¼Œåˆ™ä½¿ç”¨å½“å‰å·¥ä½œç›®å½•
        if not os.path.exists(open_fold):
            open_fold = os.getcwd()
        name, _ = QFileDialog.getOpenFileName(self, 'Video/image', open_fold,
                                              "Pic File(*.mp4 *.mkv *.avi *.flv *.jpg *.png)")
        if name:
            self.yolo_predict.source = name
            self.show_status('åŠ è½½æ–‡ä»¶ï¼š{}'.format(os.path.basename(name)))
            config['open_fold'] = os.path.dirname(name)
            config_json = json.dumps(config, ensure_ascii=False, indent=2)
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(config_json)
            self.stop()

    # é€‰æ‹©æ‘„åƒå¤´æº have one bug
    def chose_cam(self):
        self.yolo_predict.camera_run()
        # try:
        #     self.stop()
        #     MessageBox(
        #         self.close_button, title='æ³¨æ„', text='æ­£åœ¨åŠ è½½æ‘„åƒå¤´...', time=2000, auto=True).exec()
        #     # è·å–æœ¬åœ°æ‘„åƒå¤´æ•°é‡
        #     _, cams = Camera().get_cam_num()
        #     popMenu = QMenu()
        #     popMenu.setFixedWidth(self.src_cam_button.width())
        #     popMenu.setStyleSheet('''
        #                                     QMenu {
        #                                     font-size: 16px;
        #                                     font-family: "Microsoft YaHei UI";
        #                                     font-weight: light;
        #                                     color:white;
        #                                     padding-left: 5px;
        #                                     padding-right: 5px;
        #                                     padding-top: 4px;
        #                                     padding-bottom: 4px;
        #                                     border-style: solid;
        #                                     border-width: 0px;
        #                                     border-color: rgba(255, 255, 255, 255);
        #                                     border-radius: 3px;
        #                                     background-color: rgba(200, 200, 200,50);}
        #                                     ''')
        #
        #     for cam in cams:
        #         exec("action_%s = QAction('%s')" % (cam, cam))
        #         exec("popMenu.addAction(action_%s)" % cam)
        #
        #     x = self.src_cam_button.mapToGlobal(self.src_cam_button.pos()).x()
        #     y = self.src_cam_button.mapToGlobal(self.src_cam_button.pos()).y()
        #     y = y + self.src_cam_button.frameGeometry().height()
        #     pos = QPoint(x, y)
        #     action = popMenu.exec(pos)
        #     if action:
        #         self.yolo_predict.source = action.text()
        #         self.show_status('åŠ è½½æ‘„åƒå¤´ï¼š{}'.format(action.text()))
        #
        # # except Exception as e:
        # #     self.show_status('%s' % e)

    # é€‰æ‹©ç½‘ç»œæº
    def chose_rtsp(self):
        self.rtsp_window = Window()
        config_file = 'config/ip.json'
        if not os.path.exists(config_file):
            ip = "rtsp://192.168.2.72:8554/h264_ulaw.sdp"
            # ip = "rtsp://admin:admin888@192.168.1.2:555"
            new_config = {"ip": ip}
            new_json = json.dumps(new_config, ensure_ascii=False, indent=2)
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(new_json)
        else:
            config = json.load(open(config_file, 'r', encoding='utf-8'))
            ip = config['ip']
        self.rtsp_window.rtspEdit.setText(ip)
        self.rtsp_window.show()
        self.rtsp_window.rtspButton.clicked.connect(lambda: self.load_rtsp(self.rtsp_window.rtspEdit.text()))

    def voice_announcement(self):  # TTS:TextToSpeech
        self.TTS_window = TTSWindow()
        self.TTS_window.show()
        tts_dialog = threading.Thread(target=self.tts_dialog_show)
        tts_dialog.start()
        self.TTS_window.checkButton.clicked.connect(lambda: self.check_fire(self.TTS_window))
        self.TTS_window.cancelButton.clicked.connect(lambda: self.close_tts_dialog(self.TTS_window))

    def tts_dialog_show(self):
        self.TTS_window.exec()

    def tts(self):
        # è¯­éŸ³è­¦å‘Šçº¿ç¨‹
        tts_thread = threading.Thread(target=self.speak)
        tts_thread.start()

    def speak(self):
        self.engine_switch = True  # å¼€å¯æ’­æŠ¥
        while self.engine_switch:
            self.engine.say('è­¦å‘Šï¼å‘ç°ç«æºï¼')
            self.engine.runAndWait()

    def check_fire(self, TTS_window):
        self.engine_switch = False
        # æ¢å¤ç°åœº
        self.yolo_predict.fire_flag = False  # æ˜¯å¦è¯†åˆ«åˆ°ç«ç„°
        self.yolo_predict.isFirstTTS = True  # æ˜¯å¦ä¸ºç¬¬ä¸€æ¬¡è¯†åˆ«åˆ°ç«ç„°
        TTS_window.close()

    def close_tts_dialog(self, TTS_window):
        self.engine_switch = False
        # æ¢å¤ç°åœº
        self.yolo_predict.fire_flag = False  # æ˜¯å¦è¯†åˆ«åˆ°ç«ç„°
        self.yolo_predict.isFirstTTS = True  # æ˜¯å¦ä¸ºç¬¬ä¸€æ¬¡è¯†åˆ«åˆ°ç«ç„°
        TTS_window.close()

    # åŠ è½½ç½‘ç»œæº
    def load_rtsp(self, ip):
        try:
            self.stop()
            MessageBox(
                self.close_button, title='æç¤º', text='åŠ è½½ rtsp...', time=1000, auto=True).exec()
            self.yolo_predict.source = ip
            new_config = {"ip": ip}
            new_json = json.dumps(new_config, ensure_ascii=False, indent=2)
            with open('config/ip.json', 'w', encoding='utf-8') as f:
                f.write(new_json)
            self.show_status('åŠ è½½ rtspï¼š{}'.format(ip))
            self.rtsp_window.close()
            # å±•ç¤º

        except Exception as e:
            self.show_status('%s' % e)

    # ä¿å­˜æµ‹è¯•ç»“æœæŒ‰é’®--å›¾ç‰‡/è§†é¢‘
    def is_save_res(self):
        if self.save_res_button.checkState() == Qt.CheckState.Unchecked:
            self.show_status('æ³¨æ„ï¼šè¿è¡Œå›¾åƒç»“æœä¸ä¼šè¢«ä¿å­˜ã€‚')
            self.yolo_predict.save_res = False
        elif self.save_res_button.checkState() == Qt.CheckState.Checked:
            self.show_status('æ³¨æ„ï¼šè¿è¡Œå›¾åƒç»“æœå°†è¢«ä¿å­˜ã€‚')
            self.yolo_predict.save_res = True

    # ä¿å­˜æµ‹è¯•ç»“æœæŒ‰é’® -- æ ‡ç­¾ (txt)
    def is_save_txt(self):
        if self.save_txt_button.checkState() == Qt.CheckState.Unchecked:
            self.show_status('æ³¨æ„ï¼šæ ‡ç­¾ç»“æœä¸ä¼šè¢«ä¿å­˜ã€‚')
            self.yolo_predict.save_txt = False
        elif self.save_txt_button.checkState() == Qt.CheckState.Checked:
            self.show_status('æ³¨æ„ï¼šæ ‡ç­¾ç»“æœå°†è¢«ä¿å­˜ã€‚')
            self.yolo_predict.save_txt = True

    # é…ç½®åˆå§‹åŒ–  ~~~wait to change~~~
    def load_config(self):
        config_file = 'config/setting.json'
        if not os.path.exists(config_file):
            iou = 0.26
            conf = 0.33
            rate = 10
            save_res = 0
            save_txt = 0
            new_config = {"iou": iou,
                          "conf": conf,
                          "rate": rate,
                          "save_res": save_res,
                          "save_txt": save_txt
                          }
            new_json = json.dumps(new_config, ensure_ascii=False, indent=2)
            with open(config_file, 'w', encoding='utf-8') as f:
                f.write(new_json)
        else:
            config = json.load(open(config_file, 'r', encoding='utf-8'))
            if len(config) != 5:
                iou = 0.26
                conf = 0.33
                rate = 10
                save_res = 0
                save_txt = 0
            else:
                iou = config['iou']
                conf = config['conf']
                rate = config['rate']
                save_res = config['save_res']
                save_txt = config['save_txt']
        self.save_res_button.setCheckState(Qt.CheckState(save_res))
        self.yolo_predict.save_res = (False if save_res == 0 else True)
        self.save_txt_button.setCheckState(Qt.CheckState(save_txt))
        self.yolo_predict.save_txt = (False if save_txt == 0 else True)
        self.run_button.setChecked(False)
        self.show_status("Welcome~")

    # ç»ˆæ­¢æŒ‰é’®å’Œç›¸å…³çŠ¶æ€
    def stop(self):
        if self.yolo_thread.isRunning():
            self.yolo_thread.quit()  # ç»“æŸçº¿ç¨‹
        self.yolo_predict.stop_dtc = True
        self.run_button.setChecked(False)  # æ¢å¤å¯åŠ¨é”®
        self.save_res_button.setEnabled(True)  # å¯ä»¥ä½¿ç”¨ä¿å­˜æŒ‰é’®
        self.save_txt_button.setEnabled(True)  # å¯ä»¥ä½¿ç”¨ä¿å­˜æŒ‰é’®
        self.pre_video.clear()  # æ¸…ç©ºå›¾åƒæ˜¾ç¤º
        self.res_video.clear()  # æ¸…ç©ºå›¾åƒæ˜¾ç¤º
        self.progress_bar.setValue(0)
        self.Class_num.setText('--')
        self.Target_num.setText('--')
        self.fps_label.setText('--')

    # æ”¹å˜æ£€æµ‹å‚æ•°
    def change_val(self, x, flag):
        if flag == 'iou_spinbox':
            self.iou_slider.setValue(int(x * 100))  # å€¼å˜åŒ–ï¼Œæ”¹å˜æ»‘å—
        elif flag == 'iou_slider':
            self.iou_spinbox.setValue(x / 100)  # æ»‘å—å€¼å˜åŒ–ï¼Œæ”¹å˜å€¼
            self.show_status('IOU é˜ˆå€¼: %s' % str(x / 100))
            self.yolo_predict.iou_thres = x / 100
        elif flag == 'conf_spinbox':
            self.conf_slider.setValue(int(x * 100))
        elif flag == 'conf_slider':
            self.conf_spinbox.setValue(x / 100)
            self.show_status('Conf é˜ˆå€¼: %s' % str(x / 100))
            self.yolo_predict.conf_thres = x / 100
        elif flag == 'speed_spinbox':
            self.speed_slider.setValue(x)
        elif flag == 'speed_slider':
            self.speed_spinbox.setValue(x)
            self.show_status('å»¶è¿Ÿï¼š%s æ¯«ç§’' % str(x))
            self.yolo_predict.speed_thres = x  # ms

    # æ›´æ”¹æ¨¡å‹
    def change_model(self, x):
        self.select_model = self.model_box.currentText()
        self.yolo_predict.new_model_name = "./models/%s" % self.select_model
        self.show_status('æ›´æ”¹æ¨¡å‹ï¼š%s' % self.select_model)
        self.Model_name.setText(self.select_model)

    # label result
    # def show_labels(self, labels_dic):
    #     try:
    #         self.result_label.clear()
    #         labels_dic = sorted(labels_dic.items(), key=lambda x: x[1], reverse=True)
    #         labels_dic = [i for i in labels_dic if i[1]>0]
    #         result = [' '+str(i[0]) + 'ï¼š' + str(i[1]) for i in labels_dic]
    #         self.result_label.addItems(result)
    #     except Exception as e:
    #         self.show_status(e)

    # å¾ªç¯ç›‘è§†æ¨¡å‹æ–‡ä»¶æ›´æ”¹
    def ModelBoxRefre(self):
        pt_list = os.listdir('./models')
        pt_list = [file for file in pt_list if file.endswith('.pt')]
        pt_list.sort(key=lambda x: os.path.getsize('./models/' + x))
        # å¿…é¡»åœ¨æ¯”è¾ƒä¹‹å‰è¿›è¡Œæ’åºï¼Œå¦åˆ™åˆ—è¡¨ä¼šä¸€ç›´åˆ·æ–°
        if pt_list != self.pt_list:
            self.pt_list = pt_list
            self.model_box.clear()
            self.model_box.addItems(self.pt_list)

    # è·å–é¼ æ ‡ä½ç½®ï¼ˆç”¨äºæŒ‰ä½æ ‡é¢˜æ æ‹–åŠ¨çª—å£ï¼‰
    def mousePressEvent(self, event):
        p = event.globalPosition()
        globalPos = p.toPoint()
        self.dragPos = globalPos

    # è°ƒæ•´çª—å£å¤§å°åº•éƒ¨å’Œå³è¾¹ç¼˜æ‹–åŠ¨æ—¶çš„ä¼˜åŒ–è°ƒæ•´
    def resizeEvent(self, event):
        # æ›´æ–°å¤§å°æ‰‹æŸ„
        UIFuncitons.resize_grips(self)

    # å…³é—­äº‹ä»¶ é€€å‡ºçº¿ç¨‹ï¼Œä¿å­˜è®¾ç½®
    def closeEvent(self, event):
        config_file = 'config/setting.json'
        config = dict()
        config['iou'] = self.iou_spinbox.value()
        config['conf'] = self.conf_spinbox.value()
        config['rate'] = self.speed_spinbox.value()
        config['save_res'] = (0 if self.save_res_button.checkState() == Qt.Unchecked else 2)
        config['save_txt'] = (0 if self.save_txt_button.checkState() == Qt.Unchecked else 2)
        config_json = json.dumps(config, ensure_ascii=False, indent=2)
        with open(config_file, 'w', encoding='utf-8') as f:
            f.write(config_json)
        # åœ¨å…³é—­ä¹‹å‰é€€å‡ºè¿›ç¨‹
        if self.yolo_thread.isRunning():
            self.yolo_predict.stop_dtc = True
            self.yolo_thread.quit()
            MessageBox(
                self.close_button, title='æ³¨æ„', text='æ­£åœ¨é€€å‡ºï¼Œè¯·ç¨å€™...', time=3000, auto=True).exec()
            sys.exit(0)
        else:
            sys.exit(0)


if __name__ == "__main__":
    app = QApplication(sys.argv)
    Home = MainWindow()
    Home.show()
    sys.exit(app.exec())
